{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgVp6nHodhZad4as/3Jr5i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbal98/id-vs-selfie-verification/blob/main/test_face_recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install deps\n",
        "**Make sure to swith runtime-> hardwaer accel -> gpu**"
      ],
      "metadata": {
        "id": "yVRHo5Ak8XXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python dlib\n",
        "!pip install face_recognition\n",
        "import cv2\n",
        "import dlib\n",
        "import face_recognition\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2IU-myyBzh_h",
        "outputId": "60fdab9c-03d9-4e0a-8e81-6266d25779de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=6fef2e233ed4ee65baad51baa4437e5a4b9aaaee6eeabc628a36c7efdc40eb65\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload your images here"
      ],
      "metadata": {
        "id": "z4IyFoPRzhxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "Ay9_cxlt8tWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qhQgZh9ozVzB"
      },
      "outputs": [],
      "source": [
        "def load_image(file_path):\n",
        "    return cv2.imread(file_path)\n",
        "\n",
        "def detect_faces(image):\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    return detector(image, 1)\n",
        "\n",
        "def extract_frontal_photo(image_path):\n",
        "    # Load the pre-trained Haar Cascade classifier for face detection\n",
        "    face_cascade_path = 'haarcascade_frontalface_default.xml'\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + face_cascade_path)\n",
        "\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(\"Image not found or unable to load.\")\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Check if at least one face was detected\n",
        "    if len(faces) == 0:\n",
        "        raise ValueError(\"No faces detected in the image.\")\n",
        "\n",
        "    # Assume the first detected face is the frontal photo on the ID card\n",
        "    (x, y, w, h) = faces[0]\n",
        "\n",
        "    # Crop the image to the bounding box of the detected face\n",
        "    cropped_face = img[y:y+h, x:x+w]\n",
        "\n",
        "    # Display the cropped face image\n",
        "    plt.imshow(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Return the cropped face image\n",
        "    return cropped_face\n",
        "\n",
        "\n",
        "    ## Usage: extract_frontal_photo(\"/content/card.jpg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Images here"
      ],
      "metadata": {
        "id": "elCJ4e5m87Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_id_face = extract_frontal_photo(\"/content/id.jpg\")\n",
        "extracted_selfie_face = extract_frontal_photo(\"/content/selfie.jpg\")\n",
        "extracted_test_id = extract_frontal_photo(\"/content/test_id.jpg\")"
      ],
      "metadata": {
        "id": "G4VFjCrT0Zne"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compare faces"
      ],
      "metadata": {
        "id": "0qZEyQ058_CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_faces(id_face, selfie_face):\n",
        "    # Load the images\n",
        "    id_face_encoding = face_recognition.face_encodings(id_face)[0]\n",
        "    selfie_face_encoding = face_recognition.face_encodings(selfie_face)[0]\n",
        "\n",
        "    # Compare the faces\n",
        "    results = face_recognition.compare_faces([id_face_encoding], selfie_face_encoding)\n",
        "\n",
        "    return results[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "YxwrRHHM4Hgf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the cropped faces to RGB format for face_recognition\n"
      ],
      "metadata": {
        "id": "kYVwpgTu9BNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_face_rgb = cv2.cvtColor(extracted_id_face, cv2.COLOR_BGR2RGB)\n",
        "selfie_face_rgb = cv2.cvtColor(extracted_selfie_face, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Compare the faces\n",
        "match = compare_faces(id_face_rgb, selfie_face_rgb)\n",
        "print(\"Do the faces match?\", match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djqD3_s-4NRW",
        "outputId": "2f6690a8-8e21-4600-a387-cc41ff70501e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do the faces match? True\n"
          ]
        }
      ]
    }
  ]
}